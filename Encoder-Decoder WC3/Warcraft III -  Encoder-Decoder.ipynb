{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text inspired from Blizzard's Warcraft Franchise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 747168 characters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "text = open('WC3.txt', 'rb').read().decode(encoding='utf-8')\n",
    "print(f\"Length of text: {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Inspect how many unique characters appear throughout the supplied script/text data\n",
    "unique_chars = sorted(set(text))\n",
    "print(f\"{len(unique_chars)} unique characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[51, 68, 70, 58, 51, 69], [59, 62, 62, 59, 54, 51, 64]]>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Characters to demonstrate ids_from_chars\n",
    "test_chars = ['arthas', 'illidan']\n",
    "test_chars = tf.strings.unicode_split(test_chars, input_encoding='UTF-8')\n",
    "\n",
    "# Create a mapping from unique characters to indices\n",
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(unique_chars), mask_token=None)\n",
    "\n",
    "# Check that the ids were assigned correctly\n",
    "ids = ids_from_chars(test_chars)\n",
    "ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'r', b't', b'h', b'a', b's'],\n",
       " [b'i', b'l', b'l', b'i', b'd', b'a', b'n']]>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from indices to characters\n",
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "# Test on encoded examples\n",
    "test_chars = chars_from_ids(ids)\n",
    "test_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ids back to human readable text\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(747168,), dtype=int64, numpy=array([32, 64, 70, ..., 57,  4,  4], dtype=int64)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Create a dataset of the encoded text\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'I' b'n' b't' b'r' b'o' b'd' b'u' b'c' b't' b'i' b'o' b'n' b' ' b'M'\n",
      " b'o' b'v' b'i' b'e' b'\\r' b'\\n' b'\\r' b'\\n' b'N' b'a' b'r' b'r' b'a' b't'\n",
      " b'o' b'r' b':' b' ' b'T' b'h' b'e' b' ' b's' b'a' b'n' b'd' b's' b' '\n",
      " b'o' b'f' b' ' b't' b'i' b'm' b'e' b' ' b'h'], shape=(51,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'a' b'v' b'e' b' ' b'r' b'u' b'n' b' ' b'o' b'u' b't' b',' b' ' b's'\n",
      " b'o' b'n' b' ' b'o' b'f' b' ' b'D' b'u' b'r' b'o' b't' b'a' b'n' b'.'\n",
      " b' ' b' ' b'C' b'r' b'i' b'e' b's' b' ' b'o' b'f' b' ' b'w' b'a' b'r'\n",
      " b',' b' ' b'e' b'c' b'h' b'o' b',' b'\\r' b'\\n'], shape=(51,), dtype=string)\n",
      "b'Introduction Movie\\r\\n\\r\\nNarrator: The sands of time h'\n",
      "b'ave run out, son of Durotan.  Cries of war, echo,\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "# Covert the text vector into a stream of character indices\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "ids_dataset\n",
    "\n",
    "# Denote the sequence length for each input sequence\n",
    "seq_length = 50\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "# Use batch method to convert the individual characters into sequences of the desired size\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# Test the batch method\n",
    "for seq in sequences.take(2):\n",
    "    print(chars_from_ids(seq))\n",
    "    \n",
    "# Covert back to human readable text\n",
    "for seqq in sequences.take(2):\n",
    "    print(text_from_ids(seqq).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A', 'r', 't', 'h', 'a', 's', ' ', 'm', 'y', ' ', 'b', 'o'],\n",
       " ['r', 't', 'h', 'a', 's', ' ', 'm', 'y', ' ', 'b', 'o', 'y'])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sequences into input and target offsetting by one character\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "# Test the split_input_target function\n",
    "split_input_target(list(\"Arthas my boy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  b'Introduction Movie\\r\\n\\r\\nNarrator: The sands of time '\n",
      "Target:  b'ntroduction Movie\\r\\n\\r\\nNarrator: The sands of time h'\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data to generate input and target text strings\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Text the dataset\n",
    "for x,y in dataset.take(1):\n",
    "    print(\"Input: \", text_from_ids(x).numpy())\n",
    "    print(\"Target: \", text_from_ids(y).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 50), dtype=tf.int64, name=None), TensorSpec(shape=(64, 50), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into managable sequences, assigning batch size and shuffling the data.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 5000\n",
    "\n",
    "dataset = (\n",
    "    dataset.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "# Assign initial parameters\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(unique_chars)\n",
    "print(vocab_size)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the attention mechanism to be used (Bahdanau)\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        # what does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using a tf.keras.Model class\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size,embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self,inputs,states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        # If no previous state, initialise the state\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x,training=training)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Assure the vocabulary size matches the StringLookup layers\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 87) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\n",
    "        example_batch_predictions.shape,\n",
    "        \"# (batch_size, sequence_length, vocab_size)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     multiple                  22272     \n",
      "                                                                 \n",
      " gru_9 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  89175     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,049,751\n",
      "Trainable params: 4,049,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary to check the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 50, 87)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.4664326, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.04564"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a loss function to the model\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Test the loss function on example batch\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\n",
    "    \"Prediction shape: \",\n",
    "    example_batch_predictions.shape,\n",
    "    \" # (batch_size, sequence_length, vocab_size)\",\n",
    ")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)\n",
    "\n",
    "# Compare the exponetial of the mean loss to see if it is comparable to the vocab size\n",
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to save the model checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "# Only save every 10th epoch\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    period=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 27s 112ms/step - loss: 2.5097\n",
      "Epoch 2/50\n",
      "228/228 [==============================] - 27s 117ms/step - loss: 1.8160\n",
      "Epoch 3/50\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 1.5403\n",
      "Epoch 4/50\n",
      "228/228 [==============================] - 27s 116ms/step - loss: 1.3924\n",
      "Epoch 5/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 1.2965\n",
      "Epoch 6/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 1.2212\n",
      "Epoch 7/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 1.1545\n",
      "Epoch 8/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 1.0918\n",
      "Epoch 9/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 1.0271\n",
      "Epoch 10/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.9596\n",
      "Epoch 11/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.8898\n",
      "Epoch 12/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.8213\n",
      "Epoch 13/50\n",
      "228/228 [==============================] - 26s 111ms/step - loss: 0.7509\n",
      "Epoch 14/50\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.6866\n",
      "Epoch 15/50\n",
      "228/228 [==============================] - 25s 110ms/step - loss: 0.6282\n",
      "Epoch 16/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.5765\n",
      "Epoch 17/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.5345\n",
      "Epoch 18/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.5021\n",
      "Epoch 19/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.4724\n",
      "Epoch 20/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4508\n",
      "Epoch 21/50\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.4341\n",
      "Epoch 22/50\n",
      "228/228 [==============================] - 24s 104ms/step - loss: 0.4215\n",
      "Epoch 23/50\n",
      "228/228 [==============================] - 23s 99ms/step - loss: 0.4137\n",
      "Epoch 24/50\n",
      "228/228 [==============================] - 23s 99ms/step - loss: 0.4082\n",
      "Epoch 25/50\n",
      "228/228 [==============================] - 23s 98ms/step - loss: 0.4035\n",
      "Epoch 26/50\n",
      "228/228 [==============================] - 23s 99ms/step - loss: 0.3987\n",
      "Epoch 27/50\n",
      "228/228 [==============================] - 23s 99ms/step - loss: 0.3922\n",
      "Epoch 28/50\n",
      "228/228 [==============================] - 23s 99ms/step - loss: 0.3953\n",
      "Epoch 29/50\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.3958\n",
      "Epoch 30/50\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.3962\n",
      "Epoch 31/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.3902\n",
      "Epoch 32/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.3874\n",
      "Epoch 33/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.3861\n",
      "Epoch 34/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.3959\n",
      "Epoch 35/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.4020\n",
      "Epoch 36/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4088\n",
      "Epoch 37/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.4091\n",
      "Epoch 38/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4035\n",
      "Epoch 39/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.4054\n",
      "Epoch 40/50\n",
      "228/228 [==============================] - 25s 110ms/step - loss: 0.4137\n",
      "Epoch 41/50\n",
      "228/228 [==============================] - 25s 110ms/step - loss: 0.4177\n",
      "Epoch 42/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.4212\n",
      "Epoch 43/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4222\n",
      "Epoch 44/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4296\n",
      "Epoch 45/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4292\n",
      "Epoch 46/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4316\n",
      "Epoch 47/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4357\n",
      "Epoch 48/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4434\n",
      "Epoch 49/50\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 0.4541\n",
      "Epoch 50/50\n",
      "228/228 [==============================] - 25s 109ms/step - loss: 0.4631\n"
     ]
    }
   ],
   "source": [
    "# Set the epochs and train the model\n",
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "    \n",
    "    #TODO 5 - Fill in the code below to generate text\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "        \n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        \n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneStep model\n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arthus went to. He galloped his eyes to the brother. Refent of the men returned these death knight. I fear the Light shine up nothing.” he cried, denied its without discussing her at this as he was, and for a washing for all the hands of the conversation he couldn’t never foolish in the guest characters, selming and startled by the fighting royal to his life. The others more embarrassed at the bridge, a ghing, running from his mind. He slowed his unforgiving and his heart and launched for a moment, then slowly lifeless than she charged at him. Summer and confidence; it hadn’t been engineered. Somehow, impuling, drawing run upon him. World of WarCraft: Arthas: Rise of the Lich King   “Tear younges. Kael’thas was at his subject. The wrath was dizzy. He did not believe in the death knight. Although his upperested misguised misseess filled his nose for a few moments.\n",
      "\n",
      "Me- final appears in the first one that lead myself back. And if Arthas mused as the two wore about his forest. The humans sew say Mura \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 4.4760026931762695\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Generate text using a constant prompt\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([\"Arthus went to\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(\n",
    "        next_char, states=states\n",
    "    )\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
    "print(\"\\nRun time:\", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logo-generation-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
